# -*- coding: utf-8 -*-
"""Plant_Disease_Detection_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/161BgbdJf20mIClXbkRW-TU05v79qEwMo

### Mounting google drive
"""

from google.colab import drive

drive.mount('/content/drive')

!ls "/content/drive/MyDrive/Dataset"

!ls "/content/drive/MyDrive/Dataset"

"""### Importing necessary libraries"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.image import imread
import cv2
import random
import os
from os import listdir
from PIL import Image
import tensorflow as tf
from keras.preprocessing import image
from tensorflow.keras.utils import img_to_array
from tensorflow.keras.utils import array_to_img
from keras.optimizers import Adam
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Dense, Activation, Flatten
from sklearn.model_selection import train_test_split
from keras.models import model_from_json
from keras.utils import to_categorical

"""### Visualising images"""

plt.figure(figsize = (12, 12))
path = "/content/drive/MyDrive/Dataset/Apple___Black_rot"

for i in range(1, 10):
  plt.subplot(3, 3, i)
  plt.tight_layout()
  img = imread(path + "/" + random.choice(sorted(os.listdir(path))))
  plt.imshow(img)

"""### Converting images to numpy array and normalising"""

def convert(dir):
  try:
    img = cv2.imread(dir)

    if img is not None:
      img = cv2.resize(img, (256, 256))
      return img_to_array(img)
    else:
      return np.array([])
  except Exception as e:
    print(f"Error: {e}")
    return None

dir_main = "/content/drive/MyDrive/Dataset"
img_lst, lbl_lst = [], []
all_labels = ["Apple___Black_rot",
              "Pepper,_bell___Bacterial_spot",
              "Corn_(maize)___Common_rust_",]

class_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
temp = -1

for dir in all_labels:
  plant_image_list = listdir(f"{dir_main}/{dir}")
  temp += 1

  for file in plant_image_list:
    image_path = f"{dir_main}/{dir}/{file}"
    img_lst.append(convert(image_path))
    lbl_lst.append(class_labels[temp])

"""### Checking for class imbalance"""

label_count = pd.DataFrame(lbl_lst).value_counts()
label_count.head()

img_lst[0].shape

"""We notice above that the classes are fairly balanced. Imbalanced classes cause the model to biased toward the more populated class than the lower populated classes.

### Splitting the dataset into training and testing

Here we're splitting the data into 70% training and 30% testing data.
"""

x_train, x_test, y_train, y_test = train_test_split(img_lst, lbl_lst, test_size = 0.3, random_state = 10)

"""### Normalising the dataset"""

x_train = np.array(x_train, dtype = np.float16) / 255
x_train = x_train.reshape(-1, 256, 256, 3)
train_dataset_size = len(x_train)
print(train_dataset_size)
x_test = np.array(x_test, dtype = np.float16) / 255
x_test = x_test.reshape(-1, 256, 256, 3)

"""### Performing one-hot encoding on target variable"""

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

"""### Creating the model and fitting"""

model = Sequential()
model.add(Conv2D(32, (3, 3), padding = "same", input_shape = (256, 256, 3), activation = "relu"))
model.add(MaxPooling2D(pool_size = (3, 3)))
model.add(Conv2D(16, (3, 3), padding = "same", activation = "relu"))
model.add(MaxPooling2D(pool_size = (2, 2)))
model.add(Flatten())
model.add(Dense(8, activation = "relu"))
model.add(Dense(3, activation = "softmax"))
model.summary()

model.compile(loss = "categorical_crossentropy", optimizer = Adam(0.0001), metrics = ["accuracy"])

"""### Splitting dataset into validation and training data

We are now splitting the data into 70% training and 30% validation data
"""

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.3, random_state = 10)

"""[link text](https://)### Training in multiple epochs"""

epochs = 50
batch_size = 128
history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = (x_val, y_val))

model.save("/content/drive/MyDrive/Projects/Plant_Disease_Detection/Model/plant_disease_model.h5")

"""### Plotting the accuracy"""

plt.figure(figsize = (12, 5))
plt.plot(history.history["accuracy"], color = "r")
plt.plot(history.history["val_accuracy"], color = "b")
plt.title("Model Accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epochs")
plt.legend(["train", "val"])

plt.show()

print("Model Accuracy:")
scores = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {scores[1] * 100}")

"""### Making predictions on testing data"""

y_pred = model.predict(x_test)

"""### Visualising the predictions"""

img = array_to_img(x_test[11])
img

print("Original label: ", all_labels[np.argmax(y_test[11])])
print("Predicted label: ", all_labels[np.argmax(y_test[4])])
print(y_pred[2])

for i in range(100):
  print(all_labels[np.argmax(y_test[i])], " - ", all_labels[np.argmax(y_pred[i])])